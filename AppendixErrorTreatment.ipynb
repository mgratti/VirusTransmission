{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "rg = np.random.default_rng(1234)\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the treatment of uncertainties for Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us concentrate on a given value of $p_{Inf}$ and take the variable that describes if the disease has transmitted to country B, we call it $r$ and it can take discrete values:\n",
    "* $r=1$ if the disease has transmitted to country B     (at least one infected over 100 days)\n",
    "* $r=0$ if the disease has not transmitted to country B (no infected over 100 days)\n",
    "\n",
    "Let us assume (with reason) that the outcome of our simulation follows the Bernoulli distribution (see lecture 3):\n",
    "\n",
    "<img src=\"bernoulli.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "where $p$ is the true value of the probability of transmission to country B (which we previously defined *fraction*)\n",
    "and $q=1-p$. \n",
    "\n",
    "Example: $p = 0.05$, we perform 100 experiments and we get the following outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern = rg.binomial(n=1, p=0.05, size=100)\n",
    "print(bern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(bern, bins=[-0.5,0.5,1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate the mean and variance of the distribution.\n",
    "For a Bernoulli distribution we expect: \n",
    "\n",
    "$\\mu=p$, $V=p(1-p)$\n",
    "\n",
    "In this case, we only took 100 samples, so we can expect that the mean and variance of our dataset will only approximate the true mean and variance.\n",
    "\n",
    "(Note that taking the mean equals calculating the fraction of successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean={:.2f} Var={:.2f}'.format(bern.mean(), bern.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take 500 samples, we can expect a better convergence to the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bern500 = rg.binomial(n=1, p=0.05, size=500)\n",
    "print('Mean={:.2f} Var={:.2f}'.format(bern500.mean(), bern500.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given $n$ Bernoulli trials with success probability $p$, the binomial distribution gives the\n",
    "probability to observe $r$ successes and $n-r$ failures (independently of the order)\n",
    "\n",
    "<img src=\"binomial.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Please note that, in this case, the variable $r$ has a different meaning than before. It describes how many experiments will give me success (transmission of virus to Country B)\n",
    "\n",
    "Essentially, we can use the Binomial distribution (divided by 500) as the true probability distribution of our \"fraction\" variable over the 500 experiments, with: \n",
    "$p=p_{inf}$, $n=500$\n",
    "\n",
    "E.g. we take 10 samples from this distirbution (i.e. 10 possible outcomes of our experiment with 500 trials for one value of $p_{Inf}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg.binomial(n=500, p=0.05, size=10)/500.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How justified is it that we take the mean and standard deviation of this dataset and use it for Gaussian error propagation later on? \n",
    "\n",
    "Fairly justified: the distribution of the possible outcomes of our experiment with 500 trials is almost Gaussian.\n",
    "\n",
    "(In fact we know that the binomial distribution tends to the Gaussian in the limit for $n=\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials100  = rg.binomial(n=100, p=0.05, size=10000)/100.   # 10K samples of the binomial distribution with 100 trials\n",
    "trials500  = rg.binomial(n=500, p=0.05, size=10000)/500.   # 10K samples of the binomial distribution with 500 trials\n",
    "trials5000 = rg.binomial(n=5000, p=0.05, size=10000)/5000.  # 10K samples of the binomial distribution with 5000 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.hist(trials100, bins=80,  range=(0., 0.2), alpha=0.5, label='n=100')\n",
    "ax.hist(trials500, bins=80,  range=(0., 0.2), alpha=0.5, label='n=500')\n",
    "ax.hist(trials5000, bins=80, range=(0., 0.2), alpha=0.5, label='n=5000')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('n=100,  mean={:.3f} sigma={:.3f} skewness={:.2f}'.format(trials100.mean(), np.sqrt(trials100.var()), skew(trials100)))\n",
    "print('n=500,  mean={:.3f} sigma={:.3f} skewness={:.2f}'.format(trials500.mean(), np.sqrt(trials500.var()), skew(trials500)))\n",
    "print('n=5000, mean={:.3f} sigma={:.3f} skewness={:.2f}'.format(trials5000.mean(), np.sqrt(trials5000.var()), skew(trials5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the $n$ the smaller the variance and, especially, the skewness, which is zero for a perfect Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have justified that over 500 experiments the Bernoulli distribution is fairly similar to a Gaussian. \n",
    "Therefore, when we perform exercise 1., for each value of $p_{Inf}$ we perform a few runs of 500 experiments,  calculate a mean and a standard deviation and quote these as the uncertainty on our measurements. \n",
    "\n",
    "Afaik, this guarantees that errors on fitted parameters of the least square solution are also normally distributed.\n",
    "\n",
    "In turn this means that one can use standard propagation of errors to calculate uncertainty on p* starting from uncertainties of the fitted parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example measurements (taken from having run 500 sim each point)\n",
    "\n",
    "x = np.array([0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.25])\n",
    "\n",
    "y1 = np.array([0.002, 0.008, 0.014, 0.022, 0.038, 0.058, 0.064, 0.116, 0.132,\n",
    "       0.216])\n",
    "y2 = np.array([0.008, 0.006, 0.022, 0.038, 0.028, 0.068, 0.072, 0.092, 0.156,\n",
    "       0.174])\n",
    "y3 = np.array([0.006, 0.002, 0.004, 0.024, 0.05 , 0.066, 0.082, 0.114, 0.15 ,\n",
    "       0.196])\n",
    "y4 = np.array([0.006, 0.008, 0.012, 0.024, 0.03 , 0.054, 0.062, 0.124, 0.152,\n",
    "       0.204])\n",
    "y5 = np.array([0.004, 0.006, 0.02 , 0.022, 0.038, 0.064, 0.078, 0.112, 0.14 ,\n",
    "       0.25 ])\n",
    "y6 = np.array([0.006, 0.006, 0.01 , 0.028, 0.046, 0.044, 0.086, 0.106, 0.144,\n",
    "       0.208])\n",
    "yall = np.vstack((y1,y2,y3,y4,y5,y6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = yall.mean(axis=0)\n",
    "yerr = np.sqrt(yall.var(axis=0))\n",
    "y,yerr/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to try the fit to\n",
    "def poly1(x,a,b):\n",
    "  return a + b*x\n",
    "\n",
    "def poly3(x,a,b,c,d):\n",
    "  return a + b*x + c*x**2 + d*x**3\n",
    "\n",
    "def poly2(x,a,b,c):\n",
    "  return a + b*x + c*x**2\n",
    "\n",
    "def expon(x,a,b):\n",
    "  return a * np.exp(b*x)\n",
    "\n",
    "def Logistic(x,x0,L,k):\n",
    "  return L/(1+np.exp(k*(x-x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitRoutine(f,x,y,yerr=None):\n",
    "  \n",
    "  if yerr:\n",
    "    popt,pcov = curve_fit(f, x, y, sigma=yerr, absolute_sigma=True) # important to have absolute_sigma=True\n",
    "  \n",
    "  else:\n",
    "    popt,pcov = curve_fit(f, x, y) \n",
    "\n",
    "  print('\\nFitted parameters')\n",
    "  for i,ip in enumerate(popt):\n",
    "    print('i={} fitted param:\\t{:.2f}\\t+/-\\t{:.2f}'.format(i,popt[i], pcov[i,i]**0.5))\n",
    "\n",
    "  #print('Extracted covariance matrix:')\n",
    "  #print(pcov)\n",
    "  if yerr: \n",
    "    chisq = (((y - f(x, *popt) ) / yerr)**2).sum()\n",
    "    red_chisq = chisq / (len(x)-len(popt)) # ndof = number of meas - n of fitted params\n",
    "    print('\\nvalue of Chisquare          {:.3f}'.format(chisq))\n",
    "    print('value of reduced Chisquare  {:.3f}'.format(red_chisq))\n",
    "  \n",
    "  return popt,pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_2,pcov_2 = fitRoutine(poly2,x,y,yerr)\n",
    "popt_3,pcov_3 = fitRoutine(poly3,x,y,yerr)\n",
    "popt_exp,pcov_exp = fitRoutine(expon,x,y,yerr)\n",
    "popt_log,pcov_log = fitRoutine(Logistic,x,y,yerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigx = np.linspace(0.15, 0.25, 100)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(5, 5))\n",
    "\n",
    "ax.errorbar(x, y, yerr, fmt=\"none\")\n",
    "\n",
    "ax.plot(bigx,poly2(bigx,*popt_2),label='poly2 with scipy', color='red')\n",
    "\n",
    "ax.plot(bigx,poly3(bigx,*popt_3), label='poly3 with scipy', color='orange')\n",
    "\n",
    "ax.plot(bigx,Logistic(bigx,*popt_log), label='Logistic with scipy', color='blue')\n",
    "\n",
    "ax.plot(bigx,expon(bigx,*popt_exp), label='Exponential with scipy', color='black')\n",
    "\n",
    "ax.legend(loc='upper left', frameon=True)\n",
    "\n",
    "ax.set_xlabel('Value of $p_{Inf}$')\n",
    "ax.set_ylabel('Fraction of experiments')\n",
    "ax.set_title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract p* and uncertainty (treatment for poly2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly2_inv(y,a,b,c):\n",
    "  return (-b + np.sqrt(b**2 - 4*c*(a-y)) ) / (2. * c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstar=poly2_inv(0.05,*popt_2)\n",
    "print('Extracted value of p*={:.3f}'.format(pstar)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For uncertainty calculation, I use the general formula for correlated variables\n",
    "(from [wikipedia](https://en.wikipedia.org/wiki/Propagation_of_uncertainty))\n",
    "\n",
    "<img src=\"uncer_prop_withCorr.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "So I need to calculate the partial derivatives of the inverse function (I do this analytically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVec(y,a,b,c):\n",
    "\n",
    "  sq = np.sqrt(b**2 - 4 * c * (a-y))\n",
    "\n",
    "  dinv_da = -1. / sq # ok\n",
    "  \n",
    "  dinv_db = 1./(2*c) * (-1 + b / sq) # ok \n",
    "  \n",
    "  dinv_dc = -(a-y)/c * 1/sq - 1/(2*c**2)*(-b + sq) # ok\n",
    "\n",
    "  vec = np.array([dinv_da,dinv_db,dinv_dc]) #.reshape(1,-1)\n",
    "  #jac = vec * vec.T\n",
    "  \n",
    "  return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = getVec(0.05,*popt_2)\n",
    "var_pstar = pcov_2.dot(vec).dot(vec.T)\n",
    "\n",
    "print('Extracted value of p*={:.3f} +/-{:.3f}'.format(pstar,np.sqrt(var_pstar))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt_ian = np.array([0.42, -5.73, 19.64 ])\n",
    "pcov_ian = np.array([[0.0048,-0.051,0.1333],[-0.051,0.54731,-1.4347],[0.1333,-1.4347,3.7755]])\n",
    "pcov_ian         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstar_ian = poly2_inv(0.05,*popt_ian)\n",
    "pstar_ian # inverted a with c... \n",
    "vec_ian = getVec(0.05,*popt_ian)\n",
    "var_pstar_ian = pcov_ian.dot(vec_ian).dot(vec_ian.T)\n",
    "print('Extracted value of p*={:.3f} +/-{:.3f}'.format(pstar_ian,np.sqrt(var_pstar_ian))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
